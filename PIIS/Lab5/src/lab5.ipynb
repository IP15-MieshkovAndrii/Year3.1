{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics, svm\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_predict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0         M        17.99         10.38          122.80     1001.0   \n",
       "1         M        20.57         17.77          132.90     1326.0   \n",
       "2         M        19.69         21.25          130.00     1203.0   \n",
       "3         M        11.42         20.38           77.58      386.1   \n",
       "4         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         0.2419  ...         25.38          17.33           184.60   \n",
       "1         0.1812  ...         24.99          23.41           158.80   \n",
       "2         0.2069  ...         23.57          25.53           152.50   \n",
       "3         0.2597  ...         14.91          26.50            98.87   \n",
       "4         0.1809  ...         22.54          16.67           152.20   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data.csv\")\n",
    "df.drop(['Unnamed: 32', 'id'], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['diagnosis'], axis = 1)\n",
    "y = df['diagnosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set: (398, 30)\n",
      "Size of test set: (171, 30)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 42)\n",
    "print(\"Size of training set:\", X_train.shape)\n",
    "print(\"Size of test set:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Логістична регресія"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of initial Logistic Regression model :  0.9707602339181286\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "acc_lr = metrics.accuracy_score(y_test, y_pred)\n",
    "print( 'Accuracy of initial Logistic Regression model : ', acc_lr )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=10, penalty='l1', solver='liblinear')\n",
      "Accuracy of tuned Logistic Regression model :  0.9707602339181286\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "parameters = {'penalty': ['l1', 'l2','elasticnet', 'none'], \n",
    "              'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "              'solver': ['lbfgs', 'newton-cg','liblinear', 'sag', 'saga'], \n",
    "              'max_iter': [100, 200, 500, 1000]\n",
    "             }\n",
    "\n",
    "grid_obj = GridSearchCV(lr, parameters, cv=5)\n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "lr = grid_obj.best_estimator_\n",
    "print(lr.fit(X_train, y_train))\n",
    "y_pred = lr.predict(X_test)\n",
    "acc_lr_t = metrics.accuracy_score(y_test, y_pred)\n",
    "print( 'Accuracy of tuned Logistic Regression model : ', acc_lr_t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дерево рішень"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of initial Decision Tree model :  0.9298245614035088\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "acc_dt = metrics.accuracy_score(y_test, y_pred)\n",
    "print( 'Accuracy of initial Decision Tree model : ', acc_dt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(criterion='entropy', max_depth=10, max_features='log2')\n",
      "Accuracy of tuned Decision Tree model :  0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "parameters = {'max_features': ['log2', 'sqrt','auto'], \n",
    "              'criterion': ['entropy', 'gini'],\n",
    "              'max_depth': [2, 3, 5, 10, 50], \n",
    "              'min_samples_split': [2, 3, 50, 100],\n",
    "              'min_samples_leaf': [1, 5, 8, 10]\n",
    "             }\n",
    "\n",
    "grid_obj = GridSearchCV(dt, parameters)\n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "dt = grid_obj.best_estimator_\n",
    "print(dt.fit(X_train, y_train))\n",
    "y_pred = dt.predict(X_test)\n",
    "acc_dt_t = metrics.accuracy_score(y_test, y_pred)\n",
    "print( 'Accuracy of tuned Decision Tree model : ', acc_dt_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Випадковий ліс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of initial Random Forest model :  0.9649122807017544\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "acc_rf = metrics.accuracy_score(y_test, y_pred)\n",
    "print( 'Accuracy of initial Random Forest model : ', acc_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(max_depth=10, max_features='log2', min_samples_leaf=5,\n",
      "                       n_estimators=10)\n",
      "Accuracy of tuned Random Forest model :  0.9766081871345029\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "parameters = {'n_estimators': [4, 6, 9, 10, 15], \n",
    "              'max_features': ['log2', 'sqrt','auto'], \n",
    "              'criterion': ['entropy', 'gini'],\n",
    "              'max_depth': [2, 3, 5, 10], \n",
    "              'min_samples_split': [2, 3, 5],\n",
    "              'min_samples_leaf': [1, 5, 8]\n",
    "             }\n",
    "\n",
    "grid_obj = GridSearchCV(rf, parameters)\n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "rf = grid_obj.best_estimator_\n",
    "print(rf.fit(X_train, y_train))\n",
    "y_pred = rf.predict(X_test)\n",
    "acc_rf_t = metrics.accuracy_score(y_test, y_pred)\n",
    "print( 'Accuracy of tuned Random Forest model : ', acc_rf_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of initial SVM model :  0.9766081871345029\n"
     ]
    }
   ],
   "source": [
    "sc = StandardScaler()\n",
    "X_train_sc = sc.fit_transform(X_train)\n",
    "X_test_sc = sc.transform(X_test)\n",
    "\n",
    "svc = svm.SVC()\n",
    "\n",
    "svc.fit(X_train_sc, y_train)\n",
    "y_pred = svc.predict(X_test_sc)\n",
    "acc_svm = metrics.accuracy_score(y_test, y_pred)\n",
    "print( 'Accuracy of initial SVM model : ', acc_svm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1000, gamma=0.0001)\n",
      "Accuracy of tuned SVM model :  0.9824561403508771\n"
     ]
    }
   ],
   "source": [
    "sc = StandardScaler()\n",
    "X_train_sc1 = sc.fit_transform(X_train)\n",
    "X_test_sc1 = sc.transform(X_test)\n",
    "\n",
    "svc = svm.SVC()\n",
    "\n",
    "parameters = [\n",
    "    {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\n",
    "    {'C': [1, 10, 100, 1000], 'kernel': ['linear']}\n",
    "]\n",
    "\n",
    "grid_obj = GridSearchCV(svc, parameters)\n",
    "grid_obj = grid_obj.fit(X_train_sc1, y_train)\n",
    "\n",
    "svc = grid_obj.best_estimator_\n",
    "print(svc.fit(X_train_sc1, y_train))\n",
    "y_pred = svc.predict(X_test_sc1)\n",
    "acc_svm_t = metrics.accuracy_score(y_test, y_pred)\n",
    "print( 'Accuracy of tuned SVM model : ', acc_svm_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of initial KNN model :  0.9590643274853801\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "acc_knn= metrics.accuracy_score(y_test, y_pred)\n",
    "print( 'Accuracy of initial KNN model : ', acc_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(leaf_size=10)\n",
      "Accuracy of tuned KNN model :  0.9590643274853801\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "parameters = {'n_neighbors': [3, 4, 5, 10], \n",
    "              'weights': ['uniform', 'distance'],\n",
    "              'algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "              'leaf_size' : [10, 20, 30, 50]\n",
    "             }\n",
    "\n",
    "grid_obj = GridSearchCV(knn, parameters)\n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "knn = grid_obj.best_estimator_\n",
    "print(knn.fit(X_train, y_train))\n",
    "y_pred = knn.predict(X_test)\n",
    "acc_knn_t = metrics.accuracy_score(y_test, y_pred)\n",
    "print( 'Accuracy of tuned KNN model : ', acc_knn_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Initial Score</th>\n",
       "      <th>Tuned Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Support Vector Machines</td>\n",
       "      <td>0.976608</td>\n",
       "      <td>0.982456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.964912</td>\n",
       "      <td>0.976608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.970760</td>\n",
       "      <td>0.970760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K - Nearest Neighbors</td>\n",
       "      <td>0.959064</td>\n",
       "      <td>0.959064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.929825</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Model  Initial Score  Tuned Score\n",
       "3  Support Vector Machines       0.976608     0.982456\n",
       "2            Random Forest       0.964912     0.976608\n",
       "0      Logistic Regression       0.970760     0.970760\n",
       "4    K - Nearest Neighbors       0.959064     0.959064\n",
       "1            Decision Tree       0.929825     0.947368"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'Decision Tree', 'Random Forest', 'Support Vector Machines', \n",
    "              'K - Nearest Neighbors'],\n",
    "    'Initial Score': [acc_lr, acc_dt, acc_rf, acc_svm, acc_knn],\n",
    "    'Tuned Score': [acc_lr_t, acc_dt_t, acc_rf_t, acc_svm_t, acc_knn_t]})\n",
    "models.sort_values(by='Tuned Score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((398, 30), (171, 30))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df['diagnosis'] = label_encoder.fit_transform(df['diagnosis'])\n",
    "y = df['diagnosis']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 333)\n",
    "X_train.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Max Voting / Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9415204678362573, 0.9649122807017544)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf = LogisticRegression(solver='lbfgs', multi_class='multinomial', random_state=42)\n",
    "dt_clf = DecisionTreeClassifier(random_state=42)\n",
    "svm_clf = svm.SVC(probability=True, gamma='scale', random_state=42)\n",
    "\n",
    "hard_voting_clf = VotingClassifier(estimators=[('lr', lr_clf), ('dt', dt_clf), ('svm', svm_clf)], voting='hard')\n",
    "hard_voting_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_hard = hard_voting_clf.predict(X_test)\n",
    "acc_hard = metrics.accuracy_score(y_test, y_pred_hard)\n",
    "\n",
    "soft_voting_clf = VotingClassifier(estimators=[('lr', lr_clf), ('dt', dt_clf), ('svm', svm_clf)], voting='soft')\n",
    "soft_voting_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_soft = soft_voting_clf.predict(X_test)\n",
    "acc_soft = metrics.accuracy_score(y_test, y_pred_soft)\n",
    "\n",
    "acc_hard, acc_soft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9649122807017544"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf.fit(X_train, y_train)\n",
    "dt_clf.fit(X_train, y_train)\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "lr_probs = lr_clf.predict_proba(X_test)\n",
    "dt_probs = dt_clf.predict_proba(X_test)\n",
    "svm_probs = svm_clf.predict_proba(X_test)\n",
    "\n",
    "avg_probs = (lr_probs + dt_probs + svm_probs)/3\n",
    "avg_prediction = (avg_probs[:, 1] >= 0.5).astype(int)\n",
    "\n",
    "acc_avg = metrics.accuracy_score(y_test, avg_prediction)\n",
    "acc_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weighted Averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9473684210526315"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_lr = 0.4\n",
    "weight_dt = 0.15\n",
    "weight_svm = 0.45\n",
    "\n",
    "weighted_avg_probs = (lr_probs * weight_lr + dt_probs * weight_dt + svm_probs * weight_svm) / (weight_lr + weight_dt + weight_svm)\n",
    "weighted_avg_prediction = (weighted_avg_probs[:, 1] >= 0.5).astype(int)\n",
    "\n",
    "acc_weighted_avg = metrics.accuracy_score(y_test, weighted_avg_prediction)\n",
    "acc_weighted_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9649122807017544"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf.fit(X_train, y_train)\n",
    "dt_clf.fit(X_train, y_train)\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "lr_oof_pred = cross_val_predict(lr_clf, X_train, y_train, cv=5, method=\"predict_proba\") \n",
    "dt_oof_pred = cross_val_predict(dt_clf, X_train, y_train, cv=5, method=\"predict_proba\") \n",
    "svm_oof_pred = cross_val_predict(svm_clf, X_train, y_train, cv=5, method=\"predict_proba\")\n",
    "\n",
    "stacked_features_train = np.column_stack((lr_oof_pred[:, 1], dt_oof_pred[:, 1], svm_oof_pred[:, 1]))\n",
    "\n",
    "meta_model = LogisticRegression()\n",
    "meta_model.fit(stacked_features_train, y_train)\n",
    "\n",
    "lr_pred_test = lr_clf.predict_proba (X_test)[:, 1] \n",
    "dt_pred_test = dt_clf.predict_proba (X_test)[:, 1]\n",
    "svm_pred_test = svm_clf.predict_proba (X_test)[:, 1]\n",
    "\n",
    "stacked_features_test = np.column_stack ((lr_pred_test, dt_pred_test, svm_pred_test))\n",
    "final_pred = meta_model.predict(stacked_features_test)\n",
    "acc_stacking = metrics.accuracy_score(y_test, final_pred)\n",
    "acc_stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9532163742690059"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_blending, X_val, y_train_blending, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=0)\n",
    "\n",
    "lr_clf.fit(X_train_blending, y_train_blending) \n",
    "dt_clf.fit(X_train_blending, y_train_blending) \n",
    "svm_clf.fit(X_train_blending, y_train_blending)\n",
    "\n",
    "lr_pred_val = lr_clf.predict_proba(X_val)[:, 1] \n",
    "dt_pred_val = dt_clf.predict_proba(X_val)[:, 1] \n",
    "svm_pred_val = svm_clf.predict_proba(X_val)[:, 1]\n",
    "\n",
    "blender_features = np.column_stack((lr_pred_val, dt_pred_val, svm_pred_val))\n",
    "\n",
    "blender = LogisticRegression()\n",
    "blender.fit(blender_features, y_val)\n",
    "\n",
    "lr_pred_test = lr_clf.predict_proba(X_test)[:, 1] \n",
    "dt_pred_test = dt_clf.predict_proba (X_test)[:, 1]\n",
    "svm_pred_test = svm_clf.predict_proba (X_test)[:, 1]\n",
    "\n",
    "blender_test_features = np.column_stack((lr_pred_test, dt_pred_test, svm_pred_test))\n",
    "\n",
    "final_blend_pred = blender.predict(blender_test_features)\n",
    "acc_blending = metrics.accuracy_score(y_test, final_blend_pred)\n",
    "acc_blending"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9181286549707602"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "bagging_clf = BaggingClassifier(base_estimator=base_model, n_estimators=100, random_state=42)\n",
    "\n",
    "bagging_clf.fit(X_train, y_train)\n",
    "\n",
    "bagging_pred = bagging_clf.predict(X_test)\n",
    "acc_bagging = metrics.accuracy_score(y_test, bagging_pred)\n",
    "acc_bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8947368421052632"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_boost_clf = AdaBoostClassifier(base_estimator=base_model, n_estimators=100, random_state=42) \n",
    "\n",
    "ada_boost_clf.fit(X_train, y_train)\n",
    "\n",
    "ada_boost_pred = ada_boost_clf.predict(X_test)\n",
    "acc_ada_boost = metrics.accuracy_score(y_test, ada_boost_pred)\n",
    "acc_ada_boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ensemble</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Max Voting / Voting Classifier soft</td>\n",
       "      <td>0.964912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Averaging</td>\n",
       "      <td>0.964912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stacking</td>\n",
       "      <td>0.964912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Blending</td>\n",
       "      <td>0.953216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Weighted Averaging</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Max Voting / Voting Classifier hard</td>\n",
       "      <td>0.941520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bagging</td>\n",
       "      <td>0.918129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Boosting</td>\n",
       "      <td>0.894737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Ensemble     Score\n",
       "1  Max Voting / Voting Classifier soft  0.964912\n",
       "2                            Averaging  0.964912\n",
       "4                             Stacking  0.964912\n",
       "5                             Blending  0.953216\n",
       "3                   Weighted Averaging  0.947368\n",
       "0  Max Voting / Voting Classifier hard  0.941520\n",
       "6                              Bagging  0.918129\n",
       "7                             Boosting  0.894737"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "df_res2 = pd.DataFrame({\n",
    "'Ensemble': ['Max Voting / Voting Classifier hard', 'Max Voting / Voting Classifier soft', 'Averaging', 'Weighted Averaging', 'Stacking', 'Blending', 'Bagging', 'Boosting'],\n",
    "'Score': [acc_hard, acc_soft, acc_avg, acc_weighted_avg, acc_stacking, acc_blending, acc_bagging, acc_ada_boost]})\n",
    "df_res2.sort_values (by='Score', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
